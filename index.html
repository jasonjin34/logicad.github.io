<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="LogicAD project page">
  <meta property="og:title" content="logicad, research"/>
  <meta property="og:description" content="RWTH Aachen University Research"/>
  <meta property="og:url" content="https://jasonjin34.github.io/logicad.github.io/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/main_figure_v1-crop.pdf" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>LogicAD: Explainable Anomaly Detection via VLM-based Text Feature Extraction</title>
  <link rel="icon" type="image/x-icon" href="static/images/lfb.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <!-- Include MathJax for LaTeX rendering -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script type="text/javascript" id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
  <style>
    body {
      font-family: Arial, sans-serif;
      line-height: 1.6;
    }
    .section {
      padding: 2rem 1rem;
    }
    .hero.is-light {
      background-color: #f8f9fa;
    }
    .title {
      font-weight: bold;
      margin-bottom: 1rem;
    }
    .content {
      font-size: 1rem;
    }
  </style>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">LogicAD: Explainable Anomaly Detection via VLM-based Text Feature Extraction</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://github.com/jasonjin34" target="_blank">Er Jin</a><sup>1,*</sup>,</span>
                <span class="author-block">
                  <a href="https://www.unravel.rwth-aachen.de/cms/unravel/das-graduiertenkolleg/team/unravel-team/~wjact/qihui-feng/?lidx=1" target="_blank">Qihui Feng</a><sup>2,*</sup>,</span>
                  <span class="author-block">
                    <a href="https://dbis.rwth-aachen.de/dbis/index.php/user/mou/" target="_blank">Yongli Mou</a><sup>3</sup>,</span>
                  </span>
                    <span class="author-block">
                      <a href="https://kbsg.rwth-aachen.de/~gerhard/" target="_blank">Gerhard Lakemeyer</a><sup>2</sup>,</span>
                    </span>
                    <span class="author-block">
                      <a href="https://www.rwth-aachen.de/go/id/bdfr/gguid/0x7E2F13C98071384E8BC07C35B2FD9DAF" target="_blank">Stefan Decker</a><sup>3</sup>,</span>
                    </span>
                    <br>
                    <span class="author-block">
                      Oliver Simons</a><sup>4,&dagger;</sup>,</span>
                    </span>
                    <span class="author-block">
                      <a href="https://www.lfb.rwth-aachen.de/de/institute/team/stegmaier/" target="_blank">Johannes Stegmaier</a><sup>1,&dagger;</sup>,</span>
                    </span>
                    <span class="author-block">
                  </div>
                
                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      <sup>1</sup>Institute of Imaging and Computer Vision, RWTH Aachen University,
                      <sup>2</sup>Knowledge-Based Systems Group (KBSG), RWTH Aachen University,
                      <sup>3</sup>Chair of Computer Science i5 Information Systems and Databases, RWTH Aachen University
                      <sup>4</sup> Independent Author
                      <br> 
                      <span class="eql-cntrb"><small><sup>*</sup>Corresponding Authors with Equal Contribution</small></span>
                      <span class="eql-cntrb"><small><sup>&dagger;</sup>Indicates Equal Contribution</small></span>
                    </span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2501.01767" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/LogicAD_Supplymentary_Matrials.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/jasonjin34/logicAD" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (will be available soon)</span>
                  </a>
                </span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser GIF-->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      
      <div id="results-carousel">
       <div class="item">
        <!-- Your image here -->
        <center>
          <img src="static/images/main_figure_v1.jpg" alt="MY ALT TEXT"/>
        </center>
        
        <h4 class="subtitle is-6 has-text-centered" style="margin-top: 0.5em; color: gray; font-size: small;"">
             Pipeline overview of LogicAD.
        </h4>
      </div>
      
    </div>
  </div>
</div>
</div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Logical image understanding involves interpreting and reasoning
            about the relationships and consistency within an image’s
            visual content. This capability is essential in applications
            such as industrial inspection, where logical anomaly detection
            is critical for maintaining high-quality standards and
            minimizing costly recalls. Previous research in anomaly detection
            (AD) has relied on prior knowledge for designing algorithms,
            which often requires extensive manual annotations,
            significant computing power, and large amounts of data for
            training. Autoregressive, multimodal Vision Language Models
            (AVLMs) offer a promising alternative due to their exceptional
            performance in visual reasoning across various domains.
            Despite this, their application in logical AD remains
            unexplored. In this work, we investigate using AVLMs for
            logical AD and demonstrate that they are well-suited to the
            task. Combining AVLMs with format embedding and a logic
            reasoner, we achieve state-of-the-art (SOTA) performance on
            public benchmarks, MVTec LOCO AD, with an AUROC of
            86.0% and an F1-max of 83.7% along with explanations
            of the anomalies. This significantly outperforms the existing
            SOTA method by 18.1% in AUROC and 4.6% in F1-max
            score.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Combined Method Section -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Methods</h2>
        <div class="content has-text-justified">
          <h3>Text Extraction</h3>
          <p>
            The LogicAD method is based on robust text extraction. The detailed steps of text extraction can be summarized as follows:
          </p>
          <ol>
            <li>
              Generate a set of regions \( \mathbf{w}_i \), where \( i \in [1, N] \) and \( N \) represents the total number of regions of interest (ROIs), using the function \( f_{\text{GDINO}} \) with feature prompts. Each region, along with the original image, is then processed by the function \( f_{\text{AVLM}} \), \( K = 3 \) times, yielding a collection of textual descriptions \( \mathcal{T} = \{ t_1, t_2, t_3 \} \).
            </li>
            <li>
              Construct the text embedding space \( \mathcal{M} \) by applying the text embedding model, text-embedding-3-large from OpenAI, \( f_{\text{emb}} \), to \( \mathcal{T} \), resulting in:
              \[
              \mathcal{M} = f_{\text{emb}}(\mathcal{T}) = \{ \mathbf{e}_i \}_{i=1}^k
              \]
              where \( \mathbf{e}_i \) is the embedding of the extracted text. Subsequently, these text embeddings are fed into an outlier detection model, specifically the Local Outlier Factor (LOF) function \( f_{\text{LOF}} \), to generate the filtered text embedding space, denoted as \( \mathcal{T}_{\text{filter}} \). Finally, we randomly select the corresponding text from the filtered embedding space \( \mathcal{T}_{\text{filter}} \).
            </li>
          </ol>
          <div class="image-container">
            <img src="static/images/guide_cot-crop.jpg" alt="Anomaly Detection Logic">
            <div class="image-caption">Guided CoT</div>
          </div>
          
          <div class="image-container">
            <img src="static/images/text_feature_extraction-crop.jpg" alt="Anomaly Detection Logic">
            <div class="image-caption">Sample of text feature extraction pipeline</div>
          </div>


          <h3>Anomaly Text Detection</h3>
          <p>
            After the robust text extraction, we propose the following two directions for anomaly text detection:
          </p>
          <h4>1. Format Embedding</h4>
          <p>
            After extracting the text features, we use an LLM to summarize the text in <i>JSON</i> format. Both the normal/reference image \(X_{n}\) and the query image \(X_{q}\) are then fed into the embedding function \(f_{\text{emb}}\) to generate the respective embedding features \(\mathbf{\hat{e}}_n\) and \(\mathbf{\hat{e}}_q\). We then calculate the anomaly score based on the cosine similarity between these normalized embeddings as follows:
          </p>
          \[
          \text{ascore} = 1 - \langle \mathbf{\hat{e}}_n, \mathbf{\hat{e}}_q \rangle
          \]

          <h4>2. Logic Reasoner</h4>
          <p>
            Let \(\Gamma = \Sigma_{\text{norm}} \cup \Sigma_{\text{na}} \cup \Sigma_{\text{fa}} \cup \Sigma_{\text{dca}}\) be the union of all hypotheses. The anomaly detection (\(\text{AD}\)) task is then converted to a theorem-proving task:
          </p>
          <ul>
            <li>If \(\Gamma \models \neg \Sigma_0\), then we label the image as abnormal.</li>
            <li>If \(\Gamma \not\models \neg \Sigma_0\), then we label the image as normal.</li>
          </ul>
          <p>
            We use Prover9 for theorem proving. Here, \(\Gamma \models \neg \Sigma_0\) means \(\Gamma\) logically entails \(\neg \Sigma_0\), i.e., every logical model satisfying \(\Gamma\) will also satisfy the negation of \(\Sigma_0\). Since \(\Sigma_0\) is the formal description of the image, it shows that the image description contradicts the normal cases and hence the image is abnormal.
          </p>
          <p>
            To identify the actual anomaly, we look for a minimal subset of \(\Sigma_0\) which causes the anomaly, i.e., for \(\Sigma_a \subseteq \Sigma_0\), if \(\Gamma \models \neg \Sigma_a\) and for any \(\Sigma' \subsetneq \Sigma_a\), we have \(\Gamma \not\models \neg \Sigma'\), then \(\Sigma_a\) forms an explanation. Consider \(\Sigma_0\) and \(\Gamma\) defined as above with all the mentioned formulae:
          </p>
          <p>
            \[
            \Gamma \models \neg \Sigma_0 \quad \text{since both an apple and a nectarine are on the left.}
            \]
            Then \(\Sigma_a = \{ \text{left}(\text{nectarine}, 1), \text{left}(\text{apple}, 1) \}\) is a formal explanation of the anomaly since \(\Sigma_a \subseteq \Sigma_0\), and
          </p>
          \[
          \begin{align*}
              & \Gamma \models \neg (\text{left}(\text{nectarine}, 1) \land \text{left}(\text{apple}, 1)) \\
              & \Gamma \not\models \neg \text{left}(\text{nectarine}, 1) \\
              & \Gamma \not\models \neg \text{left}(\text{apple}, 1)
          \end{align*}
          \]
        </div>
      </div>
    </div>
  </div>
</section>

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{jin2025logicad,
  title={Logicad: Explainable anomaly detection via vlm-based text feature extraction},
  author={Jin, Er and Feng, Qihui and Mou, Yongli and Lakemeyer, Gerhard and Decker, Stefan and Simons, Oliver and Stegmaier, Johannes},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={39},
  number={4},
  pages={4129--4137},
  year={2025}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
